import json
import os
import sys
from unittest.mock import Mock, patch

import pytest

# Importe as exce√ß√µes que ser√£o usadas ou esperadas
from decouple import UndefinedValueError
from google.genai.errors import APIError as GoogleAPIError
from rest_framework.exceptions import APIException

# --- IMPORTANTE: Ajuste este import para o caminho real da sua fun√ß√£o ---
from analysis.services.ai_llm.analyze import analyze_with_llm

# --- Fixtures ---


@pytest.fixture
def valid_content():
    """Fixture que fornece um conte√∫do de texto v√°lido (passa na verifica√ß√£o de 100 caracteres)."""
    return (
        "Este √© um texto de exemplo com mais de 100 caracteres, usado para testar a an√°lise principal."
        * 2
    )


@pytest.fixture(autouse=True)
def mock_config_success():
    """
    Fixture (com autouse=True) que aplica um patch autom√°tico na fun√ß√£o `config`
    para retornar uma chave de API falsa em todos os testes, exceto onde for
    explicitamente sobrescrita.
    """
    # O patch deve apontar para onde `config` √© USADO
    with patch("analysis.services.ai_llm.analyze.config") as mock_conf:
        mock_conf.return_value = "fake-api-key-12345"
        yield mock_conf


@pytest.fixture
def mock_genai_client():
    """
    Fixture principal para mockar a cadeia de chamadas da API do Google.
    O mock √© configurado para simular a estrutura response.text.strip()
    """
    # 1. Mock do objeto de resposta final (o que tem o .text)
    mock_api_response = Mock()
    # 2. Mock do atributo .text
    mock_api_response.text = Mock()
    # 3. Define um retorno padr√£o para .text.strip()
    mock_api_response.text.strip.return_value = "{}"  # Default to an empty JSON string

    # 4. Mock da inst√¢ncia do cliente
    mock_client_instance = Mock()
    mock_client_instance.models.generate_content.return_value = mock_api_response

    # 5. Patch na classe 'Client'
    with patch("analysis.services.ai_llm.analyze.genai.Client") as mock_client_class:
        mock_client_class.return_value = mock_client_instance
        # 6. Yield o mock da resposta para que os testes possam configur√°-lo
        yield mock_api_response


# --- Testes de Casos de Erro e Exce√ß√£o ---


def test_analise_llm_falha_chave_api_ausente():
    """
    ‚ö†Ô∏è Testa o caso de erro onde a vari√°vel de ambiente KEY_GEMINI_API n√£o est√° definida.
    """
    with patch(
        "analysis.services.ai_llm.analyze.config",
        side_effect=UndefinedValueError("Chave n√£o encontrada"),
    ):
        with pytest.raises(APIException) as exc_info:
            analyze_with_llm("qualquer conteudo")
        assert "Chave GEMINI_API n√£o encontrada" in str(exc_info.value)


@pytest.mark.parametrize(
    "conteudo_insuficiente",
    [
        None,
        "",
        " " * 101,  # Este teste agora passa, gra√ßas √† corre√ß√£o .strip() no c√≥digo
        "a" * 99,
    ],
)
def test_analise_llm_conteudo_insuficiente(conteudo_insuficiente):
    """
    üß© Testa os casos de "guarda" (guard clause) onde o conte√∫do √© muito curto,
    nulo ou inv√°lido (menor que 100 caracteres).
    """
    resultado = analyze_with_llm(conteudo_insuficiente)
    assert resultado["llm_status"] == "CAUTELA"
    assert "texto extraido √© muito curto ou invalido" in resultado["llm_recommendation"]


def test_analise_llm_falha_api_google(valid_content):
    """
    ‚ö†Ô∏è Testa o caso de erro onde a API do Google (genai) levanta um GoogleAPIError.
    """
    with patch("analysis.services.ai_llm.analyze.genai.Client") as mock_client_class:
        mock_client_instance = Mock()

        # Adicione o argumento obrigat√≥rio `response_json`
        mock_client_instance.models.generate_content.side_effect = GoogleAPIError(
            "Erro de servidor 500", response_json={}
        )

        mock_client_class.return_value = mock_client_instance

        # Act & Assert
        with pytest.raises(APIException) as exc_info:
            analyze_with_llm(valid_content)

        assert "Erro na API da LLM: Erro de servidor 500" in str(exc_info.value)


def test_analise_llm_falha_parsing_json(valid_content, mock_genai_client):
    """
    ‚ö†Ô∏è Testa o caso de erro onde o LLM retorna uma string que *n√£o* √© um JSON v√°lido.
    """
    # CORRE√á√ÉO: Usar .text.strip.return_value
    mock_genai_client.text.strip.return_value = "Isto n√£o √© um JSON { quebrado"

    with pytest.raises(APIException) as exc_info:
        analyze_with_llm(valid_content)
    assert "Erro ao analisar o JSON do LLM" in str(exc_info.value)


def test_analise_llm_falha_inesperada(valid_content):
    """
    ‚ö†Ô∏è Testa o caso de erro gen√©rico (Exception) para qualquer falha n√£o prevista.
    """
    with patch("analysis.services.ai_llm.analyze.genai.Client") as mock_client_class:
        mock_client_instance = Mock()
        mock_client_instance.models.generate_content.side_effect = ValueError(
            "Erro inesperado no cliente"
        )
        mock_client_class.return_value = mock_client_instance

        with pytest.raises(APIException) as exc_info:
            analyze_with_llm(valid_content)
        assert "Erro inesperado na LLM: Erro inesperado no cliente" in str(
            exc_info.value
        )


def test_analise_llm_bug_recommendation_nula(valid_content, mock_genai_client):
    """
    üß© Testa o caso onde o LLM retorna {"recommendation": null}.
    Com a nova l√≥gica de `... or "N/A"`, este teste agora passa como estava escrito.
    """
    llm_json_response = {
        "summary": "Resumo",
        "risk_assessment": "Risco",
        "recommendation": None,
    }
    # CORRE√á√ÉO: Usar .text.strip.return_value
    mock_genai_client.text.strip.return_value = json.dumps(llm_json_response)

    resultado = analyze_with_llm(valid_content)

    assert resultado["llm_status"] == "BAIXO RISCO"
    assert resultado["llm_summary"] == "Resumo"
    assert resultado["llm_risk_assessment"] == "Risco"
    # Esta asser√ß√£o agora est√° CORRETA, pois (None or "N/A") √© "N/A"
    assert resultado["llm_recommendation"] == "N/A"


# --- Testes de Casos de Sucesso ---


def test_analise_llm_sucesso_alto_risco(valid_content, mock_genai_client):
    """
    ‚úÖ Testa o caminho feliz para uma recomenda√ß√£o de "ALTO RISCO" (contendo "EVITE").
    """
    llm_json_response = {
        "summary": "Resumo do conte√∫do.",
        "risk_assessment": "Detectamos v√°rios sinais de manipula√ß√£o.",
        "recommendation": "EVITE ESTE SITE E CONTE√öDO",
    }
    # CORRE√á√ÉO: Usar .text.strip.return_value
    mock_genai_client.text.strip.return_value = json.dumps(llm_json_response)

    resultado = analyze_with_llm(valid_content)

    assert resultado["llm_status"] == "ALTO RISCO"
    assert resultado["llm_summary"] == "Resumo do conte√∫do."
    assert resultado["llm_recommendation"] == "EVITE ESTE SITE E CONTE√öDO"


def test_analise_llm_sucesso_risco_moderado(valid_content, mock_genai_client):
    """
    ‚úÖ Testa o caminho feliz para uma recomenda√ß√£o de "RISCO MODERADO" (contendo "CAUTELA").
    """
    llm_json_response = {
        "summary": "Resumo.",
        "risk_assessment": "Linguagem sensacionalista.",
        "recommendation": "PROSSIGA COM CAUTELA",
    }
    # CORRE√á√ÉO: Usar .text.strip.return_value
    mock_genai_client.text.strip.return_value = json.dumps(llm_json_response)

    resultado = analyze_with_llm(valid_content)

    assert resultado["llm_status"] == "RISCO MODERADO"


def test_analise_llm_sucesso_baixo_risco(valid_content, mock_genai_client):
    """
    ‚úÖ Testa o caminho feliz para uma recomenda√ß√£o de "BAIXO RISCO" (qualquer outra).
    """
    llm_json_response = {
        "summary": "Resumo.",
        "risk_assessment": "Parece fatual.",
        "recommendation": "CONFIE NO CONTE√öDO",
    }
    # CORRE√á√ÉO: Usar .text.strip.return_value
    mock_genai_client.text.strip.return_value = json.dumps(llm_json_response)

    resultado = analyze_with_llm(valid_content)

    assert resultado["llm_status"] == "BAIXO RISCO"


def test_analise_llm_sucesso_recomendacao_lowercase(valid_content, mock_genai_client):
    """
    üß© Testa o edge case do .upper(): A recomenda√ß√£o vem em min√∫sculas.
    """
    llm_json_response = {"recommendation": "prossiga com cautela"}
    # CORRE√á√ÉO: Usar .text.strip.return_value
    mock_genai_client.text.strip.return_value = json.dumps(llm_json_response)

    resultado = analyze_with_llm(valid_content)

    assert resultado["llm_status"] == "RISCO MODERADO"


# --- Testes de Edge Cases e L√≥gica Interna ---


def test_analise_llm_truncamento_de_conteudo():
    """
    üß© Testa se o conte√∫do enviado ao LLM √© corretamente truncado em 8000 caracteres.
    """
    conteudo_longo = ("a" * 8000) + ("b" * 500)
    conteudo_esperado_no_prompt = "a" * 8000

    with patch("analysis.services.ai_llm.analyze.genai.Client") as mock_client_class:
        mock_client_instance = Mock()
        mock_api_response = Mock()

        # CORRE√á√ÉO: Simular a estrutura .text.strip()
        mock_api_response.text = Mock()
        mock_api_response.text.strip.return_value = json.dumps({"recommendation": "OK"})

        mock_client_instance.models.generate_content.return_value = mock_api_response
        mock_client_class.return_value = mock_client_instance

        analyze_with_llm(conteudo_longo)

        mock_client_instance.models.generate_content.assert_called_once()
        kwargs_da_chamada = mock_client_instance.models.generate_content.call_args[1]
        prompt_enviado_ao_llm = kwargs_da_chamada.get("contents", "")

        assert f"\n{conteudo_esperado_no_prompt}\n" in prompt_enviado_ao_llm
        assert "bbbbb" not in prompt_enviado_ao_llm


def test_analise_llm_chaves_json_ausentes(valid_content, mock_genai_client):
    """
    üß© Testa o que acontece se o LLM retornar um JSON v√°lido, mas vazio ({}).
    """
    # CORRE√á√ÉO: Usar .text.strip.return_value
    mock_genai_client.text.strip.return_value = "{}"  # JSON vazio

    resultado = analyze_with_llm(valid_content)

    # Com a nova l√≥gica `... or "N/A"`, todos os campos ausentes devem ser "N/A"
    # e o status (baseado em "" or "N/A") ser√° "BAIXO RISCO".
    assert resultado["llm_status"] == "BAIXO RISCO"
    assert resultado["llm_summary"] == "N/A"
    assert resultado["llm_risk_assessment"] == "N/A"
    assert resultado["llm_recommendation"] == "N/A"


def test_analise_llm_valores_json_nulos_ou_vazios(valid_content, mock_genai_client):
    """
    üß© Testa a l√≥gica de retorno para valores `None` ou `""`.
    """
    llm_json_response = {
        "summary": None,  # Deve se tornar "N/A"
        "risk_assessment": "",  # Deve se tornar "N/A"
        "recommendation": "OK",
    }
    # CORRE√á√ÉO: Usar .text.strip.return_value
    mock_genai_client.text.strip.return_value = json.dumps(llm_json_response)

    resultado = analyze_with_llm(valid_content)

    assert resultado["llm_status"] == "BAIXO RISCO"
    # CORRE√á√ÉO: Asser√ß√µes atualizadas para a nova l√≥gica `... or "N/A"`
    assert resultado["llm_summary"] == "N/A"  # (None or "N/A") -> "N/A"
    assert resultado["llm_risk_assessment"] == "N/A"  # ("" or "N/A") -> "N/A"
    assert resultado["llm_recommendation"] == "OK"  # ("OK" or "N/A") -> "OK"
